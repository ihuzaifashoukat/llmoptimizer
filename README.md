## llmoptimizer

Generate an `llm.txt` Markdown summary of your website’s structure and key data for LLMs. Framework-agnostic with helpers for Next.js, React, Vue, and static sites.

### Why

- Give LLMs a compact overview of your site: pages, metadata, headings, JSON-LD, locales, and key links.
- Works via crawling a live URL, reading a sitemap, or scanning a static export folder.
- Use the CLI in CI/CD or the API in build steps.

### Install

```
npm install --save-dev llmoptimizer
```

Node.js 18+ is required.

### Quickstart (CLI)

```
# Crawl a live site
npx llmoptimizer generate --url https://example.com --out llm.txt --max-pages 150

# From a sitemap
npx llmoptimizer generate --sitemap https://example.com/sitemap.xml --out llm.txt

# From a static export (e.g., Next.js `out/`)
npx llmoptimizer generate --root ./out --out llm.txt

# From a build (no crawling): scan common build dirs
npx llmoptimizer generate --build-scan --project-root . --out llm.txt
# Specify build dirs
npx llmoptimizer generate --build-scan --build-dirs dist build .output/public .next/server/pages --out llm.txt
# Filter build-scan to specific route paths
npx llmoptimizer generate --build-scan --include "/blog/*" "/docs/*" --exclude "/admin/*" --out llm.txt
```

Options:

- `--format markdown|json` (default `markdown`)
- `--theme default|compact|detailed` (default `default`)
- `--max-pages <n>` limit processed pages
- `--concurrency <n>` parallel fetches
- `--include <glob...>` / `--exclude <glob...>` simple pattern filters
- `--no-robots` ignore `robots.txt`

### Config (optional)

Create `llmoptimizer.config.ts`:

```ts
import { defineConfig } from 'llmoptimizer'

export default defineConfig({
  baseUrl: 'https://example.com',
  obeyRobots: true,
  maxPages: 200,
  concurrency: 8,
  render: { theme: 'default' },
  output: { file: 'public/llm.txt', format: 'markdown' },
})
```

### API

```ts
import {
  generateFromUrl,
  generateFromSitemap,
  generateFromStatic,
  generate,
  generateFromAdapter,
} from 'llmoptimizer'

// Crawl from a base URL
await generateFromUrl({ baseUrl: 'https://example.com', maxPages: 100, concurrency: 5, obeyRobots: true, outFile: 'llm.txt', format: 'markdown' })

// Use sitemap as seeds
await generateFromSitemap({ sitemapUrl: 'https://example.com/sitemap.xml', outFile: 'llm.txt', format: 'markdown', maxPages: 200, concurrency: 8, obeyRobots: true })

// Scan static HTML
await generateFromStatic({ rootDir: './out', outFile: 'llm.txt', format: 'markdown' })

// Directly from HTML strings
await generate([
  { url: 'https://example.com', html: '<html>...</html>' },
], { outFile: 'llm.txt', format: 'markdown', baseUrl: 'https://example.com' })

// Use framework adapter (e.g., Next.js) to infer routes and fetch them
await generateFromAdapter({
  projectRoot: process.cwd(),
  baseUrl: 'https://example.com',
  outFile: 'llm.txt',
  format: 'markdown',
  concurrency: 8,
  obeyRobots: true,
})
```

### Next.js integration

- After `next build && next export`, run: `npx llmoptimizer generate --root ./out --out ./out/llm.txt`.
- Or crawl Production: `npx llmoptimizer generate --url https://yourdomain.com --out public/llm.txt`.
- Or adapter mode (static-like routes only): `npx llmoptimizer generate --adapter --project-root . --url https://yourdomain.com --out public/llm.txt`.

Programmatic helper:

```ts
// scripts/postbuild-llm.ts
import { runAfterNextBuild } from 'llmoptimizer/next'

await runAfterNextBuild({
  projectRoot: process.cwd(),
  baseUrl: 'https://yourdomain.com',
  outFile: 'public/llm.txt',
  mode: 'adapter', // or 'static' (with staticDir) or 'crawl'
})
```

package.json:

```json
{
  "scripts": {
    "postbuild": "node scripts/postbuild-llm.ts"
  }
}
```

### Vite plugin

Add to `vite.config.ts`:

```ts
import { defineConfig } from 'vite'
import { llmOptimizer } from 'llmoptimizer/vite'

export default defineConfig({
  plugins: [llmOptimizer({ mode: 'static' })],
})
```

This writes `llm.txt` into your build output directory after build. Use `mode: 'crawl'` with `baseUrl` to fetch from production.

### What goes into llm.txt

- Header includes: "Generated By: LLMOPTIMIZER BY Huzaifa Shoukat".
- Site summary: base URL, generation time, inferred locales.
- For each page (SEO-focused):
  - Basics: URL, locale, dir, title, description, canonical
  - Last Modified (for static/build scans)
  - Metadata: robots, keywords, viewport, charset, generator
  - Social: OpenGraph, Twitter
  - Intl: hreflang alternates
  - Structure: H1–H4 headings; breadcrumbs (from JSON-LD)
  - Content: snippet and word count estimate
  - Links: internal/external counts; sample of important links with rel
  - Media: image count and missing alt count; sample of images
  - Structured Data: JSON-LD types summary

### Design & Extensibility

- Core is framework-agnostic and uses the web standard `fetch` (Node 18+).
- HTML parsing via `cheerio`. Sitemap parsing via `fast-xml-parser`.
- Adapters layer (e.g., Next.js) can infer routes for framework-aware flows.
- Output emitters support `markdown` and `json`.
- You can pass a custom markdown renderer via config or CLI template file.
- Built-in themes: `default`, `compact` (one-line-per-page), `detailed` (adds table of contents and site-wide totals).

Custom Markdown via config:

```ts
import { defineConfig } from 'llmoptimizer'
export default defineConfig({
  render: {
    markdown: (site, pages) => `# Custom llm.txt\nPages: ${pages.length}\n`,
  },
})
```

Or via CLI template file:

```ts
// llm-template.mjs
export default function markdown(site, pages) {
  return `# ${site.baseUrl || ''} (${pages.length} pages)`
}
```

Then run: `npx llmoptimizer generate --url https://example.com --template ./llm-template.mjs`

### Roadmap

- Vite/Rollup plugin hooks to auto-generate on build.
- Deeper robots.txt parsing (Allow/Disallow precedence per RFC).
- Per-page custom extractors and ignore rules.
- Dedup and content hashing for change detection.

### License

MIT

### Framework Integrations (Build-Time)

- Vite (React, Vue, Svelte, Solid, Preact)
  - Add to `vite.config.ts`:
  - Example:
  ```ts
  import { defineConfig } from 'vite'
  import { llmOptimizer } from 'llmoptimizer/vite'
  export default defineConfig({ plugins: [llmOptimizer({ mode: 'static' })] })
  ```
  - Output: `llm.txt` written to `dist/` after build. Use `{ mode: 'crawl', baseUrl: 'https://site.com' }` to crawl prod.
  - Or, scan build output without crawling: `npx llmoptimizer generate --build-scan --out dist/llm.txt`

- Next.js (App or Pages)
  - CLI (adapter mode): `npx llmoptimizer generate --adapter --project-root . --url https://yourdomain.com --out public/llm.txt`
  - Script helper:
  ```ts
  // scripts/postbuild-llm.ts
  import { runAfterNextBuild } from 'llmoptimizer/next'
  await runAfterNextBuild({ baseUrl: 'https://yourdomain.com', outFile: 'public/llm.txt', mode: 'adapter' })
  ```
  - Add to package.json: `{ "scripts": { "postbuild": "node scripts/postbuild-llm.ts" } }`
  - No-crawl build scan: `npx llmoptimizer generate --build-scan --build-dirs .next/server/pages --out public/llm.txt`

- Astro
  - `astro.config.mjs`:
  ```ts
  import { defineConfig } from 'astro/config'
  import llm from 'llmoptimizer/astro'
  export default defineConfig({ integrations: [llm({ mode: 'static' })] })
  ```

- Nuxt 3 (Nitro)
  - `nuxt.config.ts`:
  ```ts
  export default defineNuxtConfig({
    modules: [['llmoptimizer/nuxt', { mode: 'static' }]],
  })
  ```
  - For crawl mode, pass `baseUrl` and optional `outFile`.

- Remix
  - Add a postbuild script and call the helper:
  ```ts
  // scripts/postbuild-llm.mjs
  import { runAfterRemixBuild } from 'llmoptimizer/remix'
  await runAfterRemixBuild({ mode: 'crawl', baseUrl: 'https://your.app', outFile: 'public/llm.txt' })
  ```
  - package.json: `{ "scripts": { "postbuild": "node scripts/postbuild-llm.mjs" } }`

- Create React App / Any Static React
  - After `react-scripts build`, run: `npx llmoptimizer generate --root build --out build/llm.txt`

- Generic Node/Express/SSR
  - Use the generic helper:
  ```ts
  // scripts/postbuild-llm.mjs
  import { runAfterBuild } from 'llmoptimizer/node'
  await runAfterBuild({ mode: 'crawl', baseUrl: 'https://yourdomain.com', outFile: 'llm.txt' })
  ```

### Best Practices for Great llm.txt

- Clear metadata: title, description, canonical, OG/Twitter tags.
- JSON-LD: Use appropriate schema.org types for key entities.
- Information hierarchy: meaningful H1–H3 headings and concise copy.
- Internationalization: set `<html lang>` and `hreflang` alternates.
- Sitemaps: ensure up-to-date `sitemap.xml` to cover important pages.
- Robots: allow crawling of public pages that should appear in llm.txt.

### Adapter Route Params (Dynamic Routes)

- For dynamic routes (e.g., `/blog/:slug`), provide sample values so adapter mode can fetch real pages.
  - Config `llmoptimizer.config.ts`:
  ```ts
  import { defineConfig } from 'llmoptimizer'
  export default defineConfig({
    params: {
      slug: ['hello-world', 'getting-started'],
      id: ['1', '42']
    },
    // per-route param overrides
    routeParams: {
      '/docs/:lang/getting-started': { lang: ['en', 'fr'] }
    },
    // explicitly add patterns if adapter misses them
    routes: ['/pricing', '/blog/:slug']
  })
- SvelteKit
  - Uses Vite plugin (same as above). You can also leverage adapter mode for route inference:
  ```bash
  npx llmoptimizer generate --adapter --project-root . --url https://yourdomain.com --out static/llm.txt --route-params ./params.json
  ```
  - `params.json` example: `{ "slug": ["welcome"], "lang": ["en","fr"] }`

- Angular
  - Use a postbuild script with the generic Node helper or CLI:
  ```json
  {
    "scripts": {
      "build": "ng build",
      "postbuild": "npx llmoptimizer generate --root dist/your-app --out dist/your-app/llm.txt"
    }
  }
  ```
  - Or crawl production: `npx llmoptimizer generate --url https://yourdomain.com --out llm.txt`
  ```
  - Or via CLI: `--params ./params.json` where `params.json` is `{ "slug": ["hello-world"], "id": ["1","2"] }`.
  - Route-specific: `--route-params ./route-params.json` where `{ "/docs/:lang/getting-started": { "lang": ["en","fr"] } }`.

### GitHub Actions (CI)

Use the example workflow at `.github/workflows/llmoptimizer.yml.example` and adapt it to your build output folders (`dist/`, `build/`, etc.). It builds your project, runs llmoptimizer in static mode, and uploads `llm.txt` as an artifact.
